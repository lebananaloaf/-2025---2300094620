## 第二讲：线性表

### 线性结构

- 线性结构：{𝑎0, 𝑎1, … , 𝑎𝑛−1}
- 特征
    - **有序，有限元素序列**
    - 每一个元素有**唯一**的前驱和后继
    - 唯一一个开始节点
    - 唯一一个终止节点
    - 其他节点是内部节点
- 

- 特点
    - 均匀性
        - 每一个数据元素具有相同的数据类型和长度
    - 有序性
        - 相对位置的关系是线性的
- 下标用0 开始计数，下标表示元素的位置
- 表尾是an-1
- n为线性表的长度，n=0为空表

### 顺序表

- 定义：向量，是元素在内存中连续存放的线性表
- 特点
    - 元素顺序的储存在连续储存空间中
    - 每一个元素有一个唯一的下标
    - 顺序表的最长度为定值
    - 通过下标可以读取指定位置，时间复杂度为0（1）
- 支持操作
    - 
- 创建顺序表
    
    - 创建过程是：分配一块存储，并且记录容量
    - 一旦分配存储块，就有了固定的大小
- 访问顺序表中的元素
    - 判断给定i是否在合法范围内
        - 不合法：非法访问
        - 合法：取得i值
    - 元素的地址计算公式
        - 
    - 元素大小通常可以静态确定（如元素是整数，实数，或包含若干大 小确定的元素的复杂结构）
    - 以O(1)的代价的完成
- 顺序表：表尾：增加/删除元素
    - 尾端加入：append(x), O(1)
        - 检查表是否满，表满的时候操作失败
        - 吧新数据存入元素存储区的第length个单元
        - 将元素计数变量length加一
    - 尾端删除元素：pop(): O（1）
        - 将length-1
- 顺序表增加元素：任意位置: insert(i, x)
    - 逐个后移后面的元素，知道腾出指定位置的时候将元素放入
    - 

- 顺序表中删除元素：随机位置：delete(i)
    - 顺序逐个前移后面元素，直到所有元素连续存储
    - 删除元素自然被覆盖
    - 

- 顺序表插入删除的复杂度分析
    - 

顺序表实例：

- List
    - 基于下标的元素访问和更新操作，复杂性为O（1）
    - 允许任意加入元素：不会出现表满情况
    - 加入新元素的过程中，元素下标索引不变
    - 基本约束
        - 只能采用连续存储：为了维持O（1）的元素访问并维持元素的顺序
        - 要能容纳任意多元素，必须在表满时更换一个更大的存储区
- 动态扩容机制时间复杂度
    - when：在容量达到k的幂+1时进行扩容
    - 方案：扩容时，新容量是旧容量的k倍，k是大于1的固定值
        - 需要复制的元素是
            - 
        - 
- 其他操作的时间复杂度
    - 元素访问和赋值，尾端加入和尾端（切片）删除是O(1) 操作
    - 一般元素加入，切片，表拼接（extend）等都是O(n) 操作。
    - pop 操作默认情况是尾端删除返回，为O(1)，指定任意位置为O(n)
    - len( ) 是O(1) 操作

### 链表

- 采用链式存储机构的线性表
- 通过后继引用把一串存储节点连城一个链

## 第三讲：字符串

### 字符串的基本概念

Creating a string in pythong

- s1= "123"
- s2="data and algorithm"
- s3 = ""helloworld awefawefawef"
- s4 = ""

字符串的术语表

- 串的长度：字符串中字符个数
- 空串：长度为零的字符串
- 子序列：在s1中，任意个字符**按顺序组成**的序列s2称为s1的子序列
- 字串和主串：字符串s1中任意个**连续字符组成的序列**s2是s1的子串
    - s1=“Hello world”, s2=“Hello”
- 字符在串中的位置：字符在串中第一次出现时的位置
- 子串在主串中的位置：字串在串中第一次出现时，第一个字符的位置
- 两个字符串相等的充分条件：长度相等，对应位置上的字符相等

字符串vs线性表的区别于联系

- 串的数据对象：字符集
    - 每一个节点包含一个字符
- 线性表操作为单个元素，串可以以一个整体作为操作对象
- 线性表的储存方式**同样适用于字符串**

### Python 中的字符串

Python: string类型（不可变类型）

字符串创建

- 字符串可以用单引号 '、双引号 " 或三引号 '''/""" 创建。
- 例如：s1 = 'Hello‘ s2 = "World" s3 = """This is a multi-line string"""
- 不可变类型的变量: 一经创建，不可修改其值

字符串操作

- 一些操作不需要修改字符串：
    - 切片（如s\[1:4\]）、查找子串（如s.find("is")
- 对于修改操作，通过创建新的字符串来实现对字符串的“修改”
    - 最常见的拼接操作，即创建一个新的字符串
        - 例如，S = “Python ” + “is ” + “awesome”
    - 拼接大量字符串时，造成性能下降
        - 使用join运算：S = “ ”.join(\[“Python”, “is”, “awesome"\])

str类型的常用方法

- \_len__ 返回串的长度
- \__add__ 两个字符串的拼接
- \__eq_\_, \__gt_\_, \__lt__ 字符串的相等/大于/小于运算（字典序）
- split 以指定分隔符（默认空格）分割字符串
- join 将序列中的元素以指定字符串连接
- strip 移除字符串两侧的空格
- find 在字符串中检索子串

### 模式匹配算法

#### 问题定义

- 模式匹配的定义
    - 有两个串：t = t0 t1…tn-1 (target) 和 p = p0p1…pm-1 (pattern) ，
    - 在t中找出和p相同的子串。此时，t称为“目标”，而p称为“模式”
- def match(target: string, pattern: string );
    - 匹配成功：t中存在等于p的子串，返回子串在t中的位置
    - 匹配失败：返回一个特定的标志（如-1）

#### 朴素模式匹配brute force

思想

- 用P中的字符依次于T中的字符比较
    - 如果P\[0:m\] == T\[0:m\]，则匹配成功;
    - 否则，将p右移一个字符，用p中字符从头开始与t中字符
    - 如此反复执行，直到下面两种情况之一：
        - 到达某步时，P\[0:m\] == T\[i: i+m\]，匹配成功；
        - 将P移到无法与T继续比较为止，则匹配失败
- 

算法时间效率分析

target串长度为n，pattern串长度为m

Scenario 1:匹配失败

- 最坏情况：每趟匹配皆在最后一个字符不等，且有n-m+1趟匹配(每趟 比较m个字符），**共比较m\*(n-m+1)次。**
- 通常m<=n，因此最坏时间复杂度O(n\*m)
- 最好情况：比较n-m+1次 \[每趟只比较第一个字符\]

Scenario 2:匹配成功

- 最好情况：m次比较
- 最坏情况：与匹配失败的最坏情况相同，即比较m\*(n-m+1)次。

**因此，朴素模式匹配算法的时间复杂度为O(m\*n)**

#### **KMP 算法**

求出公共前后缀

- prefix and suffic all equal the same

Next array

- Used to compare with target and to jump to part of the array rather than start over

总结：时间复杂度为O(m), m为pattern长度

边界情况：i == -1 代表了什么？

- 即在上一轮匹配中，i = 0，next\[0\] = -1，而后 i=next\[i\] 赋值为-1
- 表示模式串中第一个字符的比较就发生失配
- T也无需再比较当前位置，向后移动一位
- 将next\[0\]设置为-1，让程序多循环一轮，就方便地实现了这一点

总结：时间复杂度为O(n), n为target长度

KMP 算法时间复杂度分析 总结

- 假设pattern的长度为m，target的长度为n（通常m<n)
- 计算next数组的时间复杂度为O（m）
- 匹配过程的时间复杂度为O（n）
- KMP算法总体的时间复杂度为O（m+n）
- 对比于burte force O（m\*n）

#### 改进KMP

如果我们发现P\[i\]和T\[j\]失配，所以我们需要将T\[j\]对比于P\[k\]，但是如果pi=pk的话，那么肯定是失配的，所以需要继续向左移

改进的KMP提前发现并且优化了这一点

## 第四讲：栈

### 栈的定义与操作

- 有次序的数据项集合
- 数据项的加入和移除都在同一端发生
- Last in first out
    - 时间越短离栈顶越近。时间越长离栈底越近
- 栈仅允许一段操作

栈的基本操作

- Stack()：创建一个空栈，其中不包含任何数据项
- push(item)：将item数据项加入栈顶，无返回值
- pop()：将栈顶数据项移除，返回栈顶的数据项，栈被修改
- peek()：“窥视”栈顶数据项，返回栈顶的数据项但不移除，栈不被 修改
- isEmpty()：返回栈是否为空栈
- size()：返回栈中有多少个数据项

##### 栈的实现方式

- 用户自定义类型
- Stack: 设定为python 的class
- 使用list来实现
- 设定栈顶和栈底
    - 将list的任意一段设置为栈顶 （index =0 or -1）
    - 通常末端作为栈顶(index = -1)

### 栈与递归

递归定义

- 将问题分解为规模更小的相同问题
- 算法流程中自己调用自己

递归三定律

- 递归算法必须有一个基本结束条件
    - 递归出口：最小规模问题的直接解决
- 递归算法必须向基本结束条件演进
    - 减小问题规模
- 递归算法必须调用自身

栈溢出：stack overflow

- 递归失败的情形
    - 没有设置正确的递归终止条件，或者终止条件无法达到
    - 首发不收敛，问题规模没有变小
    - 问题规模过大或者算法效率过低，在达到终止条件之前已经耗尽内存

### 栈的应用

#### 括号匹配

- 问题
    - 括号一定要平衡
        - 每一个开括号一定要有一个对应的闭括号
        - 每对开闭括号要正确的嵌套
- 方法：
    - 从左到右扫描，最近打开的做括号，应该匹配到最先遇到的有括号
    - 第一个左括号应该匹配到最后一个右括号

更多种括号的匹配

#### 十进制转换为二进制

解决思路：

- 十进制转换为二进制，采用的是“除以2”的算法 – 将整数不断除以2，每次得到的余数就是由低到高的二进制位

note: x进制 is reversed from calclulation

note: using digits like a dictionary

#### 前缀，中缀和后缀表达式

prefix expression

- Look from right to left, that is the order of importance

Postfix expression

- Look from right to left, that is the order of importance

操作符的次序完全决定了运算的次序

中缀表达式转换为前缀和后缀形式

- 先来考虑全括号的中缀表达式
    - A+B\*C = (A+(B\*C))
    - 转换为后缀表达式
        - 将每一对括号内的唯一的操作符移植到最后
        - 删除所有括号，得到的就是后缀表达式
    - 转换成前缀表达式
        - 将每一对括号内的唯一的操作符移植到最前
        - 删除所有括号，得到的就是前缀表达式
    - 把更多的操作符移动到相应的有括号处代替之，再删去左括号，整个表达式就完成到了后缀表达式的转换
        - 
    - 将操作符转移到左括号的位置代替，删掉所有有括号，得到了前缀表达式
        - 
- SUMMARY：中缀表达式转换成前缀或者后缀只需要两个步骤
    - 将中缀表达式转换成全括号形式
    - 将所有的操作符移动到子表达式所在的做括号或者有括号，并代替，再删除所有括号
    - 

通用中缀转后缀算法

- 思路
    - 在转换过程中，操作数（A,b,c,1,2,3)没有变化
    - 需要考虑优先级的问题，优先级高的会先出现
        - 需要先保存操作符，和第二个扫描到的操作符进行优先级对比，还有可能会反转次序输出
    - 括号可以忽略优先级问题，直接出现
        - 所以遇到左括号，操作符的优先级提升，扫到对应的右括号，就输出这个操作符
    - 解题思路：
        - 操作符：\*, /, + , - , ()
        - 操作单词：A,B,C
        - 从左到右扫描个字符，采用一个栈来暂存未处理的操作符
        - 栈顶的操作符是最近存进去的，当遇到一个新的操作符的时候，需要跟栈顶的操作符进行优先级对比
- 解题流程

1.  创建空栈opstack用于暂存操作符
2.  创建空表用于保存后缀表达式
3.  用split方法，将中缀表达式转换为一个一个单词的列表
4.  从左到右扫描中缀表达式的单词列表
    1.  如果单词是操作数，直接添加到后缀表达式列表的末尾
    2.  如果单词是左括号（，将操作符压入opstack栈顶
    3.  如果单词是右括号）将opstack栈顶弹出，加入到输出列表尾端，repeat until碰到左括号
    4.  如果单词是操作符，压入opstack栈顶
        1.  压入之前，尽享比较与栈顶操作符的优先级
        2.  如果栈顶的高于或等于它，就要反复弹出栈顶操作符，加入到输出列表末尾，直到栈顶的操作符优先级低于它
5.  中缀表达单词列表扫描结束后，将opstack栈中的所有剩余操作符一次弹出，添加到输出列表尾端
6.  把输出列表用join的方式并称后缀表达式字符串，算法结束

后缀表达式求值

思路

1.  从左到右扫描
2.  暂存操作数，碰到操作符的时候，再将暂存的两个操作数进行实际的计算

代码思路

1.  创建空栈operandsStack 暂存操作数
2.  将后缀表达式用split方式分解单词 的列表
3.  从左到右扫描单词列表
    1.  如果单词是一个操作数，转换成int，压入operandStack栈顶
    2.  如果单词十一阿哥操作符，弹出两个操作数，先弹出的是右操作数，后弹出的是左操作数，计算后将值重新压入栈顶
4.  单词列表扫描结束后，表达式的值就在栈顶
5.  弹出栈顶的值

## 第五讲：队列

### 定义和操作

#### 什么是队列

- 一种有次序的数据集合
- 特征：
    - 新数据项的添加总发生在一端（通常是尾端）
    - 数据项的移除总是发生在另一端（通常叫首端）
    - First in first out: 新加入的数据项必须在尾端等待，等待时间最久的事队首

名词

- 头：允许进行删除的这一端
- 尾：允许进行插入的这一端
- 空队列：队列中没有任何元素
- 进队列：队列的插入操作
- 退队列：队列的删除操作

#### 队列操作定义

- Queue()：创建一个空队列对象，返回值为Queue对象；
- enqueue(item)：将数据项item添加到队尾，无返回值；
- dequeue()：从队首移除数据项，返回值为队首数据项，队列被修改；
- is_empty()：测试是否空队列，返回值为Boolean；
- size()：返回队列中数据项的个数。

Queue 的物理实现

- 顺序队列
    - 顺序表实现
    - 出对入队操作：出队：复杂度1，入队：复杂度n
- 链式队列
    - 单链表实现
    - 出队入队操作，时间复杂度都是1

#### 顺序储存实现Queue

思想

1.  采用list 来容纳queue的数据项
2.  将list的首端作为队列的尾端
3.  list的末端作为队列首端
4.  enqueue复杂度：O（n）
5.  dequeue复杂度：O（1）

### 链式存储实现Queue

单链表实现队列

- 连接指针的方向事从队头到队尾
- 队头在链头，队尾在链尾
- 队空的条件：front ==rear==None

入队操作

- 在连标尾部插入元素
- 队列为空时特殊处理
- 时间复杂度仅O（1）

出对操作dequeue：

- 相当于连标头部删除元素
- 队列仅有一个元素时特殊处理
- 时间复杂度O（1）

### 例题讲解

#### 约瑟夫问题

问题：you're in a circle, if you're at the x position when the ball is given to you, you're eliminated

实现Josephus算法的步骤：顺序表

1.  建立顺序表
2.  维护报数的变量，来模拟问题的报数流程
    1.  变量应该模拟环结构，到最后一个人还会传给第一个人
3.  送代删除表中元素，知道只剩余一个人

算法时间分析度分析：最多i-1个元素移动，需要n-1次，(n-1)+(n-2)+……+1 = n(n-1)/2 => O(n2 )

实现算法步骤：循环链表

1.  建立循环链表
2.  出列算法
    1.  利用一个引用来维护当前的报数位置，初始为第s个节点
    2.  送代操作，直至剩余随后一个人
        1.  沿着循环链表后移，模拟一次报数过程
        2.  删除节点，并将当前报数位置后移

时间复杂度分析：

- 创建链表，求第s个结点，求n个第m个应出列的元素
- O(n) + O(s) + O(mn) = O(mn)

Using queues

#### 打印任务

对象：打印任务，打印队列，打印机

- 打印任务的属性：提交时间，打印页数
- 打印队列的属性：具有FIFO性质的打印任务队列
- 打印机的属性：打印速度，是否忙

如何对问题进行建模

过程：生成和确定打印任务

- 确定生成概率
- 实例为每小时会有10个学生提交的20个作业，这样，概率是每 180秒会有1个作业生成并提交，概率为每秒1/180

过程：实施打印

- 当前的打印作业：正在打印的作业
- 打印结束倒计时：新作业开始打印时开始倒计时，回0表示打印完毕，可以处理 下一个作业

模拟时间

- 统一的时间框架：以最小单位均匀流逝的时间，设定结束时间
- 同步所有过程：在一个时间单位内，对生成打印任务和实施打印两个过程中各仅处理一次

模拟流程

1.  创建打印队列对象
2.  时间按照秒单位流逝
    1.  按照既定概率1/180产生打印任务，如果有任务产生，则记录任务时间戳， 加入打印队列。
3.  如果打印机空闲，打印队列中的打印任务，则：
    1.  从打印队列中移除队列手打印任务，教给打印机
        1.  将打印任务的生成时间和当前时间对比，活的等待时间
        2.  记录这个任务的等待时间
        3.  根据打印任务的页数，决定需要的打印时间
    2.  如果打印机忙，就进行1秒钟的打印
    3.  如果打印机的任务打印完成，打印机进入空闲状态
4.  时间用尽，开始统计平均等待时间

顺序表实现

链表实现

#### 双端队列deque

- 是一种次序的数据集，和队列相似但是两端都可以称为首端和尾端
- 数据可以从队首加入也可以从队尾加入
- 

deque定义操作

- Deque()：创建一个空双端队列
- add_front(item)：将item加入队首
- add_rear(item)：将item加入队尾
- remove_front()：从队首移除数据项，返回值为移除的数据项
- remove_rear()：从队尾移除数据项，返回值为移除的数据项
- is_empty()：返回deque是否为空
- size()：返回deque中包含数据项的个

实现deque功能

- 官方实现

#### 回文词判定

- 使用deque
    - 将需要判定的词从队尾加入deque
    - 从两端同时一处字符判定是否相同，直到deque剩下0或者1个字符

滑动窗口

- 有一个长度为n的数的序列，序列上有一个大小为k的滑动窗口从序列最左端移动到最右端。
- 窗口每次向右滑动一个数
- 请输出窗口在每一个位置时窗口内的最大值和最小值

问题分析

## 第六讲：二叉树

### 树和二叉树概念

树的分解

- 有根，枝，和叶三个部分

树的特点

- 层次化
    - 顶部：更普遍
    - 底部：更独特
- 节点和节点之间是隔离，独立的
- 每一个叶节点都具有唯一性

树的逻辑结构

- 包含n个节点的有穷集合K，在K上定义了一个关系r，关系r满足以下条件
    - 有且仅有一个节点K0，没有前驱，这个是**根**
        - 除了根以外，其他节点对于关系r中都**有且仅有一个前驱**

树的逻辑表示

- T = (N,R)
    - 节点集合：{ A, B, C, D, E, F, G, H, I, J}
    - N上的关系 R = { &lt;A,B&gt;, &lt;A, C&gt;, &lt;A, D&gt;, &lt;C, E&gt;, &lt;D, F&gt;, &lt;D, G&gt;, &lt;E, H&gt;, &lt;E, I&gt;, &lt;I, J&gt;}
    - 

基本术语

- 父节点，子节点，边
    - 节点y是节点x的一颗子树的根，则**x称作y的父节点**
        - y是x的子节点
        - 有序对&lt;x, y&gt; 称作从x到y的边
- 兄弟节点
    - 具有同一父母节点
    - 树t中b, c d 是兄弟节点，f ,g 是兄弟节点， e f 不是兄弟节点
    - 
- 祖先，子孙
    - 若y在节点x的一个子树中
    - x是y的祖先，y是x的子孙
- 路径，路径长度
    - 对树上任意两个节点Vi，Vj必然存在唯一不重复的节点序列{𝑉𝑖 , 𝑃1, 𝑃2, … , 𝑃𝑚, 𝑉𝑗}，使得𝑉𝑖 和𝑃1之间有边，𝑃𝑚和𝑉𝑗之间有边， 𝑃𝑘和𝑃𝑘+1之间有边，这个节点 序列就被称作为𝑉𝑖到𝑉𝑗的路径。
    - 路径上边的数量被称作是路径 长度。
- 节点的层数、树的高度
    - 层数：根为第 0 层
        - 其他节点的层数等于其父节点的层数加 1
    - 深度/高度：层数最大的叶节点的层数
        - 也有些定义是上面的数值+1（取决于是否把根节点算上）
- 节点的度数、树的度数
    - 节点的子女个数叫作节点的“度数” 。
    - 树中度数最大的节点的度数叫作“树的度数”
- 树叶、分支节点
    - 度数为0的节点称作“树叶” （又叫终端节点）
    - 度数大于0的节点称作“分支节 点”或非终端节点
    - 注意，节点的度数为1时，虽然 只有一个子女，也叫分支节点。 这两个术语对于根节点也不例外
- 无序树、有序树
    - 对子树的次序不加区别的树叫作“无序树”
    - 对子树之间的次序加以 区别的树叫作“有序树”
        - 例如在下图中，按无序树的概念t和t’是同一棵树，按有序树的概念则 是不同的树

- 节点的次序
    - 在有序树中可以从左到右地规定节点的次序
    - 例如下图中，
        - 节点B，C，D是从左到右排序的；可以说节点C是节点B 右边的节点，是节点D左边的节点
        - 节点C的所有子女都在节点B及其子女的右边，而在节点D及其子女的 左边
        - 按从左到右的顺序，可以把一个节点的子节点中最左边的节点简称 “长子” ，长子右边的节点称为“次子” ， …

二叉树的递归定义

- 节点有限集合：要不然是：
    - 节点是空集
    - 由一个根和两颗不相交分别称作为这个根的左子树和右子树的二叉树组成

二叉树vs树

- 二叉树和树石两种数据结构
- 主要差别
    - 二叉树中节点的子树要区分为左子树和右子树吗，即使在节点只有一颗子树的情况下也要明确指出该子树石左子树还是右子树
    - 对于树来说，两棵都是相同的
- 度为2 的有序树并不是二叉树
    - 第一子节点被删除，第二子节点就变成了第一子节点

满二叉树

- 如果一棵二叉树的任何节点，或者是树叶，或者恰有**两棵**非空子树，则此二叉树称为满二叉树
- 

完全二叉树

- 若一棵二叉树最多只有最下面的两层节点度数可以小于2
- 最下面的节点都集中在最左侧的位置上

扩充二叉树

- 把原二叉树的节点都变为度数为2的分支节点
- 如果原节点的度数为2，则不变
- 度数为1，则增加一个分支
- 度数为0，增加两个分支

- 外部节点：新增的节点
- 内部节点：原有的节点
- 外部路径长度E：再扩充的二叉树里从根到每个外部节点的路径长度之和
- 内部路径长度I：在扩充的二叉树里从根到每个内部节点的路径长度之和

二叉树的基本性质

1.  在非空二叉树的第i层上至多有2^i个节点
    1.  这一层有多少节点
2.  深度为k的二叉树最多有2^ (k+1) - 1个节点
3.  对于任何一棵非空的二叉树，如果叶节点个数为n0，度为2 的节点个数为n2，则有n0=n2+1
4.  具有n个节点的完全二叉树的深度k为
5.  对于具有n个节点的完全二叉树，如果按照从上到下，从左到右的顺序对书中所有节点从1开始变好，则对于任意的序号为i的节点有：
    1.  如果i＞ 1 ，则其父节点的序号为 i // 2；
        1.  如果i = 1 ，则其是根节点，它没有父节点。
    2.  如果2i≤n，则其左子节点的序号为2i；
        1.  如果2i＞n，则其没有左子节点。
    3.  如果2i+ 1 ≤n，则其右子节点的序号为2i+1；
        1.  如果2i+ 1 ＞n，则其没有右子节点。

1.  在满二叉树中，叶节点个数比分支节点个数多1。
2.  在扩充的二叉树里，新增加的外部节点的个数比原 来的内部节点个数多1
3.  对任意扩充二叉树，E 和 I 之间满足：E = I + 2n， 其中n是内部节点个数。

### 二叉树的存储机构

二叉树的实现

- 顺序表示
- 链式表示

完全二叉树的顺序表示

- 完全二叉树的顺序存储
    - 所有节点按层次顺序依次存储在连续的存储单元中
    - 根据一个节点的存储地址可以算出它的左右子女，父母的存储地址，如同存储了相应的指针一样
- 顺序表是春促完全二叉树最简，最节省空间的存储方式
    - 完全二叉树的顺序存储，再存储结构上是线性的，但是在逻辑结果上依然是二叉树型结构

一般二叉树的顺序表示

- 增加空间点来构造一棵完全二叉树，再以二叉树的方式存储
- 接近于完全二叉树的形态，需要增加的空节点数目不多，则也可采用顺序表示

完全二叉树的顺序表示

- 用一组林阿絮的存储单元来存放二叉树中间的节点

二叉树的链式存储结构

- 同样可以用类似链表的节点链表法来实现树
    - 每个节点保存根节点的数据项以及指向左右子树的链接
- 定义一个binary tree类
    - 成员key来保存节点数据项
    - 成员left/right child 保存左/右的引用

insert

### 二叉树的遍历算法

二叉树的遍历

- 指按某种方法访问二叉树中的所有节点，使每个节点被访问一次且只被访问一次
- 遍历二叉树的过程实际上就是把二叉树的节点放进一个线性序列的过程
- 按照遍历的顺序，可以将遍历方法分成：
    - 深度优先遍历：depth first raversal
        - 按照深度方向，尽可能深的访问节点，然后回溯
        - 按照访问根结点的时机，进一步分成：前序，中序，后序
    - 广度优先遍历 (breadth-first traversal)
        - 按照层次顺序，逐层访问所有节点

深度有限遍历

- 前序遍历
    - DLR
        - 先访问根
        - 按前序次序遍历访问左子树
        - 按照前序次遍历右子树
    - - 此二叉树的前序序列为：A B D C E G F H I
        - 将按前序次序对一棵二叉树遍历得到的线性表称为这棵二 叉树的前序序列
    

- 中序遍历
    - 对称序法
        - 按堆成序次序遍历左子树
        - 访问根
        - 按照堆成序次访问右子树
    - 
    - Inorder Traversal is a method to traverse a tree such that for each node, you first traverse its left subtree, then visit the node itself, and finally traverse its right subtree.
    - 
- 后序遍历
    - (1) 按后序次序遍历左子树；
    - (2) 按后序次序遍历右子树；
    - (3) 访问根。

代码

二叉树基本结构

广度优先算法BFS

前序遍历

中序遍历

后续遍历

### 二叉堆

- 优先队列
    - VIP可以插队
    - 优先队列的出队dequeue操作根队列一样，都是从队首出对
    - 数据项的次序是由优先级来确定的
        - 高优先级的数据项排在队首，
        - 低优先级的数据项排在后面
        - 入多操作比较复杂， 需要根据数据项优先拍到队列的前方

二叉队binary heap实现优先队列

- 二叉队数据结构
    - 能攻将优先队列的入队和出队复杂度都保持在O（log n）
- Special type of complete binary tree
    - all levels are filled except for the last level, which is filled from left to right
    - This allows for fast access to the minimum or maximum element.
- There are two types of binary heaps, min heap and max heap
    - min heap: value of the root node is the smallest, property is true for all subtrees
    - Max heap: value of the root node is the largest, applies for all subtrees
- efficient for insertion and deletion operations
    - 
    - 
    - 
    - 
- ADT BinaryHeap的操作定义如下：
    - BinaryHeap()：创建一个空二叉堆对象；
    - insert(k)：将新key加入到堆中； –
    - findMin()：返回堆中的最小项， 最小项仍保留在堆中； –
    - delMin()：返回堆中的最小项， 同时从堆中删除； –
    - isEmpty()：返回堆是否为空； –
    - size()：返回堆中key的个数； –
    - buildHeap(list)：从一个key列表 创建新堆
- 用完全二叉树实现堆
    - 
    - Heap order
        - 初始化
            - 
        - insert(key)
            - 如果加到列表末尾，无法保持堆的次序
            - 需要将新的key沿着路径上浮到正确的位置
            - 上浮不会影响其他路径节点的堆次序
            - 
            
        - Delmin()
            - 现已出最小的key，通常是根
            - 保持完全二叉树的性质，用最后一个节点来代替跟节点
            - 解决方法：将新的跟节点沿着路径下沉，直到比两个子节点都笑
                - 下沉的路径选择：如果比子节点大，那么选择较小的子节点交换下沉

- - - BuildHeap(1st)：从无序表中生成堆
            - 用下沉法，能够将总代价控制在O（n）
            - 

## 第七讲：Huffman 树

问题的提出

- 数据通信二进制编码问题
    - 设需要编码的字符集合d = { d1，d2，…，dn } ，d中各种字符出现的频率w = { w1，w2，…，wn } ，要对d里的字符进行二进制编码，使得

1.  通信编码总长最短
2.  若di≠dj，则di的编码不可能是dj的编码的前缀。（这样就使 得译码可以一个字符一个字符地进行，不需要在字符与字符 之间添加分隔符）
    1.  

- 解决方案1
    - 定长编码：所有的字符都具有相同的编码长度
        - 优点
            - 编码简单，译码简单
        - 缺点
            - 对于每个字符出现频率不等概率的情况下，定长编码不好
            - 经常出现的字符编码长度短，不常出现的长些，信息川的编码长度会减少

- 解决方案2
    - 不定长编码
        - 假如出现频率分布为{p1 , p2 , …., pm}，频率最大的字符编码位数应该最小
        - 假定各个字符得到的编码位数为{l1 ,l2 ,…,lm}，则总的信息串的长度为：
            - 
        - 难点
            - 必须保证任何字符的编码都不是其他字符编码的前缀
            - 避免出现二义性问题

哈夫曼树

- 定义
    - •设有一组实数｛w1 , w2 , w3 ,…, wm｝，现构造一棵以wi（i = 1, 2, …，m）为权的m个外部结点的扩充的二叉树， 使得该树带权外部路径长度最小。
    - 
    - 
    - 
- 构建哈夫曼树
    - 哈夫曼算法
        - 
        - 
    - 顺序表示
        - 假设外部节点有m个，那内部节点有m-1个
        - Huffman树一定有2m-1个节点
        - 用2m-1个元素的一维数组可以存储huffman树
        - 

## 二叉搜索树

主要用途：快速的搜索

- 常用名称：二叉搜索树：BST

### 二叉搜索树定义

- 假设存储在二叉树中元素有多个field，其中一个field称为K的领域作为搜索的一句，二叉树定义为下
    - 是一个空树
    - 具有以下性质的二叉树
        - 对于任何节点，设其值为K
        - 这个节点的左子树的任意节点都小于K
        - 这个节点的右子树的节点值都大于K
        - 左右子树叶分别为BST

### 二叉搜索树上的操作

#### 检索

- 从跟节点开始，在二叉搜索树中检索值K
    - 如果跟节点存储的值为K，检索结束
    - 如果K小于跟节点的值，只需要搜索左子树
    - 如果K大雨跟节点的值，只搜索右子树
- 一直持续直到找到K或者遇到树叶

时间复杂度：O（n）

#### 插入

- 是指待插入节点为K
    - 从跟节点开始
        - 如果跟节点是空的，K插入，结束
    - 如果K小于跟节点的值，则从二叉搜索树的左子树插入
    - 如果K大于，从右子树插入
- 保证节点插入后复合二叉搜索树的定义

时间复杂度：O（n）

#### 删除

- 删除后仍要播啊吃二叉树的排序特征

情况

1.  也即诶点可以直接删除，其父节点的相应指针设为空

1.  只有一个子女的节点p被删除时，分为以下情况
    1.  p是q的左子节点p只有左节点或者右节点
    2.  p是q的右子结点，p只有左节点或者右节点
    3.  可以让子女直接代替

1.  被删除结点 p 的左右子女都不空。
    1.  要找一个可以遵守二叉搜索树的性质的节点
        1.  比 p 左子树中的所有结点都大，比p的右子树的所有 结点都小（或不大于）。
    2.  可以找：
        1.  左子树中最大者
        2.  右子树中最小者

- 删除的基本思想
    - 若没有右子树
        - 从左子树的根代替被删除的节点
    - 若有右子树
        - 在右子树中使用中序遍历的第一个节点temppointer
    - 若temppointer没有左子树
        - 删除该结点只需用temppointer的右子树代替 temppointer，然后用temppointer结点代替待删除的结点pointer

#### 二叉搜索树的实现

节点和链接结构

- 需要用到BST和TreeNode两个类
    - BST的root成员引用跟节点TreeNode
- class BinarySearchTree
    - root引用TreeNode对象
    - size表示节点总个数
    - \__iter_\_（self)实现迭代器功能

Tree only cares about it's smoll structure: node, left child, right child

BST only cares about the whole structure, the size, the root order

二叉搜索树的实现：BST.put 方法

put(key, value)：插入key构造BST

- 先查看BST是否是空的
    - 如果是空的：key就是跟节点
    - 不是：调用递归函数put（key，value，root）来放置key
- put（key, value, current_node)：
    - 如果key比currrent_node.key小，put到current_node左子树
        - 如果没有左子树，key变成左子节点
    - 如果key比currrent_node.key大，put到current_node右子树
        - 如果没有左子树，key变成左子节点

BST.get 方法

- 按照key来取value，根据树中找到key所有的节点
    - 从root开始，递归向下，直到找到，或者下到最底层的叶节点叶未找到
- get
    - 查看root是否存在
    - 调用_get
- \_get方法
    - 空引用返回none
    - 匹配当前节点：成功
    - 否则递归进入左/右子树

BST.delete

- 首先查看树中有多少节点，如果超过一个，就用_get找到要删除的节点，然后调用_delete
- 如果只有一个节点，查看key是否可以匹配上，如果匹配就删除，不匹配就报错

delete function:

\_delete

- 分为三个情景
    - 节点没有子节点
        - 直接删除

- - 节点有一子字节点
        - 将唯一的子节点上移，代替被删除的节点的位置
        - 区分几种情况
            - 被删除的节点的子节点是左节点还是右节点
            - 被删除的节点本身是父节点的左还是右
            - 被删除的节点本身就是跟节点吗

- - 节点有两个子节点
        - 找另一个合适的节点来代替被删节点
        - 代替的是右子树最小的那个
        - 后续节点最多只有一个子节点

所有的程序的时间效率由高度决定，o（h）

### 最佳二叉树

- 目的：平均查找长度最小
    - 查的更多的：放的靠近根
    - 查的更少的：放的远一点
- 检查概率的同时，对序列进行排序，然后按照二分法依次的插入关键码
- 问题：静态，经过若干次插入删除后会失去平衡，检查性能变坏
- 需要保持动态的平衡，高的检索效率

平衡二叉搜索树：AVL树的定义

- Key插入时一直保持平衡的二叉搜索树
- AVL树的实现中，需要对每一个节点跟踪平衡因子balance factor
    - 平衡因子是根据节点的左右子树的高度差来定义
    - Balancefactor = height(left_subtree) - height(right_subtree)
    - right heavy: balance facotr>0
    - rigth heavy: balance factor <0

平衡树

- 每一个节点的平衡因子都在-1，0，1之间

在平衡树操作过程中，有节点的平衡因子超出范围，则需要进行一个重新平衡的过程

- 也要保持BST性质

可以说AVL树的搜索时间复 杂度为O(log n)

AVL树的实现

- 如何保持AVL树的平衡性质

1.  新的key必定以叶节点形式插入AVL中
    1.  也节点的平衡因子是0，所以无需要平衡
    2.  但是会影响父节点的平衡因子
        1.  如果作为左子节点：平衡+1
        2.  右子节点：平衡-1
    3.  影响随着父节点一直传递上去到跟节点
2.  将AVL树作为BST树子类实现，TreeNode中加入balance_factor
3.  重新定义_put

AVL树的实现：balance

- 主要手段：通过选装将不平衡的树进行平衡
- - 保持BST性质
- 

- - 看左重或者右重进行不同方向的旋转，同时更新相关父节点引用
    - 更新旋转后被影响节点的平衡因$子
- 如果是一个右重的子树，左旋转
- 更复杂的情况
    - 心跟节点将就跟节点作为右子节点，但是新的跟节点原来已经有右子节点，需要将原有的右子节点重新定位
    - 原油的右子节点D改到旧跟节点E的左子节点
    - E的左子节点旋转后一定是空的

## 第九讲：树和森林

### 树的定义

树的递归定义

- 树石包含有限节点的非空集合，其中有且仅有一个根结点
- 进包含一个节点的集合是一棵树，跟就是该节点
- 在树中，根意外的任何其他节点，被分成若干个不相交的子集，**每个子集都是一棵树，称为子树 (subtree)**
- **空树**：不包含任何节点的树

树vs二叉树

- 树中的边、高度、深度、度数、父子结点、层次等概念， 和二叉树中的类似。
- 有序树和无序树
    - 树可以是有序的：有第一子树，第二子树，等
    - 删除第一子树，第二子树顶替成为第一子树
    - 如果规定树的各自子树之间不存在顺序，则称该树是无序树

### 森林的定义

- 森林是空集或者**不相交的树的集合**
- 森林也通常是有序的，即有第1棵树、第2棵树、第3棵树 之分。
    - 森林中每棵树的根彼此称为“兄弟”；
    - 如果将两棵树中将根结点连接到一个父节点，便得到一个树。

### 树和森林的存储表示

树和森林的存储表示

- 父指针表示法
- 子表表示法
- 长子-兄弟表示法：常用

#### 父指针表示法

- 树或者森林组成一个节点顺序表，每一结点包含父节点的下表
    - 根节点的值设置为-1，因为没有父节点
- 无序树用这种方法表示

note

- 如果两个节点达到一个根结点，那么他们肯定在同一棵树中
- 如果找到的根结点不同，那么两个节点就不再同一棵树中

父指针表示法的优点

- 容易找到父节点和所有的祖先
- 比较节省存储空间

缺点

- 没有表示出节点之间的次序
- 找节点的子女和兄弟比较费事：需要变差整个数组

父指针表示法的改进

- 为了表示有序树，按一种遍历次序在数组中存放节点
- 常见的方式是依次存放树的前序序列  
    

在改进的父指针表示法的树中求右兄弟结点的位置

#### 子表表示法

- 整棵树或者森林组成一个节点顺序表，其中每一个节点使用数组或者链表**记录该节点的所有子节点**

在子表表示法中求有兄弟的位置

子表表示上求父节点的位置

优势

- 方便找到父节点的所有子节点

缺点

- 由子节点找到父节点更困难

如果要将若干个子树合并成一个新树

- 子表表示法需要考虑调整合并后树的子表
- 父指针只需要提哦啊证树的父指针

#### 长子兄弟表示法

- 每个节点存储
    - 节点的值
    - 最左子节点
    - 右侧兄弟节点指针

note

- 每个节点包括了子节点信息，也包括了兄弟的信息
- 比子表表示法洗哦啊率更高
- 也称作左子右兄表示法

优点

- 方便找到子女，找到兄弟
- 找到全部子女很容易

缺点

- 找到父节点比较麻烦
- 可以再为节点加一条指向父节点的指针

### 树和森林的遍历

树的遍历

- 定义：按照某一规律系统的访问树的所有节点，并且使每个节点恰好被访问一次：遍历
- 在遍历树的过程中，如果将各个结点按其被访问的先后顺序排列起 来，则可得到一个包括所有结点的线性表
- 本质：将非线性结构转换为线性结构。

#### 遍历方法

- 深度优先遍历
    - 前序
    - 中序
    - 后序
- 广度优先遍历
    - 按照层次顺序访问

#### 前序遍历

- 先访问根结点，然后从左到右按前序次序遍历根结点的每棵子树
- 长子-兄弟表示法下的前序遍历：

#### 中序遍历

- 按中序次序遍历根结点的最左子树
- 访问根结点；
- 从左到右按中序次序遍历根结点的其它各子树
- 长子-兄弟表示法下的中序遍历

#### 后续遍历

- 从左到右按照次序遍历根节点的每颗子树
- 访问根节点
- 长子兄弟表示法：

#### 深度优先遍历的特点

- 相同点：在三种遍历序列中，兄弟结点的左右输出顺序不变
- 不同点：只有祖先和子孙之间的相对次序（输出顺序）可能有所不同 –
    - 在前序遍历序列中，结点的所有子孙都紧密排列在该**结点的右边；**
        - 假定post(n)表示结点n在前序序列中的位置，desc(n)表示结点n的子孙个数， 则结点x是结点n的子孙的充分必要条件为： post(n)+desc(n) ≥ post(x) > post(n)
        - 从 n 开始往右数 desc(n) 个位置
        - 这 **一整段** 都是 n 的子孙
        - 不多不少
    - 在后序遍历序列中，结点的所有子孙都紧密排列在**该结点的左边**
        - 假定post(n)表示结点n在后序序列中的位置，desc(n)表示结点n的子孙个数， 则结点x是结点n的子孙的充分必要条件为：
        - post(n)-desc(n) ≤ post(x) < post(n)
        - 在 n 的左边
        - 连续 desc(n) 个
        - 全是它的子孙

#### 广度优先遍历

- 先访问层数为0的结点，然后从左到右逐个访问层数为1的结点，依此类推，直到访问完树中的全 部结点。
- 按广度优先遍历所得到的线性表叫作树的层次序列
- 特点：
    - 在层次序列中，层数较低的结点总是排在层数较高的结点之前
    - 同层结点的左右次序还保持着，非同层结点的左右次序已被破坏

#### 森林的遍历

- 森林的遍历方法有两种：前序遍历和后序遍历
    - 前序遍历
        - 访问森林中第一棵树的根结点；
        - 前序遍历第一棵树的所有子树；
        - 前序遍历除去第一棵树之后的子森林。

- awefawfe
    - 后续遍历
        - 后序遍历第一棵树的所有子树；
        - 访问森林中第一棵树的根结点；
        - 后序遍历除去第一棵树之后的子森林。

### 树和二叉树转换

- 森林与二叉树一一对应
    - 任何森林都唯一地对应到一棵二叉树；
    - 反过来，任何二叉树也都唯一地对应到一个森林
- 森林对应的二叉树中：
    - 一个结点的左子节点，是原来森林中的长子
    - 右子节点是原来森林中的下一个兄弟
    - 即：左孩子、右兄弟

对森林中 **每一个结点 n**：

1.  🌿 **左子节点 = n 在原森林中的第一个孩子（长子）**
2.  🌿 **右子节点 = n 在原森林中的下一个兄弟**
3.  🌿 没有的就设为 None

👉 这套规则叫：

**Left-Child Right-Sibling（LCRS）表示法**

二叉树转换到森林

- 左节点是子女节点
- 右节点是sibling
- 根节点的右节点是另外个树

### 并查集

- 用父节点表示法表示的树构成的森林
- 主要用于解决的问题：一些元素分布在若干个互不相交的 集合(等价类)中，需要多次进行以下操作：
    - (1) 合并(Union) a, b两个元素所在的集合
    - (2) 查询(Find) 一个元素在哪个集合
    - (3) is_connected (a,b):判断两个元素a和b是否属于同一个集合

**集合的表示**

- 并查集通过森林来表示多个集合，每个集合是一个树结构。每个节点存储其父节点的指针，根节点的父节点指向自身。
- **如果两个节点的根节点相同，则它们属于同一个集合。**
- 关键操作
    - 查找操作（Find）：通过不断向上查找父节点，直到找到根节点。
    - 合并操作（Union）：将一个集合的根节点连接到另一个集合的根节点上，作为另一个集合的根节点的子节点。

等价类的求解问题

- 性质
    - 自反性：任何元素必须和自身相关。
    - 对称性：如果 a和 b相关，则 b 和 a也必须相关。
    - 传递性：如果 a和 b相关，且 b和 c相关，则 a和 c必须相关。
- 并查算法可以很容易地构建等价类
    - 开始时，每个元素都在独立的只包含一个结点的树中，而它自己就 是根结点
    - –对于一个等价对中的两个元素，判断是否在同一棵树中：
        - 如果是，由于它们已经在同一个等价类中，不需要作变动
        - 否则两个等价类可以用 UNION 函数归并
- Union操作：合并S1 , S2 等价类，将S1根节点的父指针指向 S2根节点

按秩合并

- Find、Union操作的代价都取决于目标结点到根节点的距离， 与所有树的最大高度有关。
    - 最坏情况下，树退化为线性结构，复杂度将变成O(n)的
- 按秩合并规则
    - 合并两棵树时，将较矮的树合并到较高的树中去，将矮树的根节点 的父指针指向高树的根
    - 即便如此，两棵一样高的树合并时仍然会导致新树的高度增加

#### 路径压缩

- 在查找过程中，可以将路径上的所有节点直接连到根节点
- 这样可以显著减少树的高度，进一步优化查找效率
- 在Find操作中递归实现路径压缩：
    - 对父节点递归调用，即查找父节点的根节点，并将路径上的所有结 点的父指针都指向根，然后将自己父指针也指向根
    - 在根结点处达到递归的终点

并查集的效率分析

- 使用路径压缩，在多次Find操作后，大部分的结点都变成 了根的子节点，或者离根很近，Find操作的速度就会大大 提升
- • 可以证明单靠路径压缩，Find 操作的均摊复杂度是O(log n)
- 加上按秩合并规则，Find操作的均摊复杂度基本上可以做 到O(1)

## 第十讲：字典与检索

### 检索问题的基本概念

检索：在一个数据结构中**查找关键码值等于给定值的元素**

- 数据结构中的元素可能包含不止一个属性，检索过程**只需要针对其中的个别属性**，称为检索的关键码

检索的结果

- 如果找到，检索成功
- 否则检索失败，数据结构中不存在符合要求的元素

检索问题

- 不同种类的检索
    - 精确匹配查询（exact-matching query）：在数据结构中查找关键码值与查询值相等的所有元素。
    - 范围查询（range query）：在数据结构中查找关键码值属于**某个指定范围内**的所有元素。

检索和字典

- 字典(Dictionary)是元素的有穷集合，其主要的操作为对 元素的检索。
- 字典中的每个元素由两部分组成，分别称为**元素的关键码(key)和属性 (attribute)**。
    - Key --> attribute
    - 关键码本质上是一个特殊的属性
    - 必须保证字典中的每个元素具有唯一的关键码
        - 比如：学号
        - 可以通过关键码来查询元素的其他属性
        - 如果有两个元素关键码相同，我们就无法区分这两个元素
- 字典分类
    - 静态字典：字典一经建立就基本固定不变，主要的操作就是字典元素的检索
        - 为静态字典选择存储方法主要考虑检索效率、检索运算的简单性
        - 在实际应用中，有时要考虑字典的插入和删除操作，所以静态字典 无法满足要求
    - 动态字典：经常需要改动的字典
        - 对于动态字典，存储方法的选择不仅要考虑检索效率，还要考虑字 典元素的插入、删除运算是否简便

检索算法的效率

- 如何评价一个检索算法的效率
    - 检索过程中关注的基本操作是关键码的比较
    - 衡量检索算法效率的主要标准是：检索过程中关键码的平均比较次 数，即平均检索长度 (Average Search Length, ASL) ，定义为：
        - 
        - n是元素的个数；pi是查找第i个元素的概率；ci是算法为了找到第i个 元素所需的比较次数。
        - 除非特别声明，一般假定各元素的检索概率相等，即pi=1/n

检索算法

- 分类
    - 基于线性表的算法
        - 顺序检索
        - 二分检索
    - 基于散列表的方法
        - 散列检索
    - 树索引法
        - 在原油数据结构之外，将所有关键码额外组织为树结构，称为索引，可以用于加快增删改查操作
            - 通常用于动态增删的场景
            - 包括：二叉搜索树，B树、B+树、红黑树、字典树等

### 顺序检索

基本思想

- 顺序检索是基于**线性表**的检索方法
- 从线性表的一端开始顺序扫描，将元素的**关键码和给定值比较**，
    - 如果相等，则检索成功
- 当扫描结束时，还未找到关键码等于给定值的元素，则检索失败

平均搜索长度ASL

- 再一次检索操作当中，平均需要进行的关键码对比次数
- 若找到的是第i个元素，则比较次数为ci=i。因此
- 

优点

- 算法实现简单，最基础的检索方法
- 顺序检索不要求字典中的元素的有序性，适用场景更广

缺点

- 平均检索长度较大，复杂度为O(n)
- 特别是当n很大时，检索效率较低

顺序检索的改进

- 当P1 ≥ P2 … ≥ Pn时，顺序检索需要使ASL最小，应该保持概率最大的 元素在最前面，概率最小的元素在最后面。
- 改进1
    - 把最近检索的元素放到第一个位置。
- 改进2
    - 如果无法预先知道各个元素的查找概率，则可以 用检索成功次数代替查找概率
        - 当检索元素成功时，其检索成功次数加1
        - 保持检索成功次数最大的元素在前面，检索成功次数最小的元素在 最后面。

### 二分检索

基本思想

- 要求线性表已经按照关键码顺序排序
- 将字典中间位置上元素的关键码 key’和给定值 key 比较，若
    - key’==key，则检索成功；
    - key’ > key，在字典前半部分中继续进行二分法检索；
    - key’ < key，在字典后半部分中继续进行二分法检索。
- 二分检索的实质是逐步缩小查找区间。

过程

- 分别用low和high表示当前查找区间的下界和上界
- 每次取 mid = (low + high) // 2

时间复杂度分析

- 
- 二分检索的过程恰好是在判定树中从根到检索结点的路径， **关键码的比较次数取决于该结点在二叉树中的层数**
- 假定总结点数n=2 h - 1， 即层数h=log2 (n+1)，则描述折半检索的判定 树是一棵高度为h-1的满二叉树。
    - 根结点为第0层
    - 第 i 层的结点数量为 2 i ，查询需要的比较次数为 i+1
- 假定各个结点的检索概率相等
    - 其中hi表示第i个结点的层数。
- 当n很大时，得到：ASL ≈ log2 (n+1)-1 = O(log n)
- 

优点

- – 二分检索的效率要高于顺序检索。比较次数少，检索速度快。

缺点

- 要求待检索按关键码排序，且只适用于顺序存储结构；
- 对于大型的表，排序一次的计算成本十分昂贵。需要依据检索操作 的频繁程度来衡量进行额外的排序是否值得。
- 在动态场景，即字典的插入删除操作频繁的场景下，维护顺序表的 有序性的成本也较高。
    - 此时可以采取二叉搜索树等基于树索引的检索方法。

分块查找

- 基本思想：“按块有序” ，即在块的级别上有序
    - 设线性表中共有 n 个数据元素，将表分成 b 块
    - 额外设置一个索引表，记录每一块的最小或最大的关键码
    - 前一块最大关键码必须小于后一块最小关键码
    - 每一块中的关键码不一定有序
- 顺序与二分法的折衷
    - 先在索引表中二分查找所在的块，然后在块中顺序查找目标元素
    - 既有较快的检索，又有较灵活的更改

分块检索为两级检索

- – 先在索引表中确定待查元素所在的块，ASLb
- 然后在块内检索待查的元素，ASLw
- 假设在索引表使用二分检索，在块内使用顺序检索
    - 
    - 

分块查找优点VS缺点

- 优点
    - 插入、删除相对较易
    - 没有大量记录移动
- 缺点
    - 增加一个辅助数组的存储空间
    - 初始线性表分块排序同样需要代价
    - 当大量插入/删除时，或结点分布不均匀时，速度下降

比较：顺序检索 & 二分检索

- 虽然二分查找在时间复杂度上优于顺序查找，但也要考虑 到对数据项进行排序的开销
    - 如果一次排序后可以进行多次查找，那么排序的开销就可以摊薄。
    - 但如果数据集经常变动，查找次数相对较少，那么可能还是直接用 无序表加上顺序查找来得经济
- 所以，在算法选择的问题上，光看时间复杂度的优劣是不 够的，还需要考虑到实际应用的情况。

### 散列检索

散列法(hashing)的基本思想：

- 直接根据记录的内容得到其存储位置
- 插入关键码为key的字典元素时，按一个确定的散列函数 h 计算哈希 值 h(key)，并把 h(key) 作为该元素的存储地址，即散列地址。
- use the key itself to directly determine where the record is stored
- computes an adress, doesn't compare keys one by one
- 索时，同样根据 h(key) 得到关键码所在元素的存储地址。

散列法也称哈希法、杂凑法。

- 用散列法表示的字典。
- 散列表中的每一个存储位置，称为槽（slot），可以用来保存数据项。
- inserting a dictionary element with key
    - apply has function to key
    - result is hash value
    - has value is used as storage address
    - the element is stored at that address in the hash table

碰撞处理

- 如果要插入新元素44，其哈希值为0，就会被分配到已有元素 77所在的槽中。
- 这种现象称为碰撞(Collision)，发生碰撞的两个(或多个)关 键码称为同义词。
    - – 即对于两个不相等的key1, key2，散列函数使得 h(key1) = h(key2)
- • h(key)的值域所对应的地址空间称为基本区域。
- 发生碰撞时，同义词可以存放在基本区域中未被占用的单 元，也可以放到基本区域以外另开辟的区域（溢出区）

散列检索主要需要解决的问题

1.  定义散列表和散列函数
    1.  散列函数：散列表如何检索
    2.  检索效率如何？检索效率与哪些因素有关？
2.  解决碰撞
    1.  对于任意的散列函数，都可能出现“碰撞”现象
    2.  碰撞发生时如何处理？

散列函数的选择标准

- 散列函数应该将关键字均匀映射到到整个地址空间中，从而尽可能 减少碰撞。即落在任意一个槽中的概率应该均等。
- 散列函数本身的计算应该尽可能简单
- 散列函数应该使得任意关键字的哈希值都落在表长范围内。

完美的散列函数

- 给定一组数据项，如果一个散列函数能把每个数据项映射到不同的 槽中，那么这个散列函数就可以称为“完美散列函数”
- 对于固定的一组数据，总是能想办法设计出完美散列函数
- 但如果数据项经常性的变动，很难有一个系统性的方法来 设计对应的完美散列函数。

常见的散列函数

- 直接定址法
- 数字分析法
- 平方取中法
- 折叠法
- 除留余数法
- 基数转换法

#### 直接定址法

- 关键字的线性函数，h(key) = a \* key + b
- 
- 适用于关键码分布基本连续情况。若关键码分布不连续，容易造成 空单元，存储空间浪费

数字分折法

- 关键码的位数远多于存储区的地址码位数，这时可以对各位进行分 析，丢掉分布不均匀的位而留下均匀的位作为地址。
- 例1：关键码为 395003、395010、395012、395085、395097
    - 前四位相同，后两位随机分布。故可以取后两位构成散列函数，得到的散 列地址为（03，10，12，85，97）
- 例2：大学学生学号
    - 2300094620
    - 前缀编码了年级、院系等信息，分布较不均匀。后几位通常是随机均匀分 布的，可以作为散列地址
- 通常用于已知记录关键码，并且关键码各位分布已经知道的情况， 适合于静态的字典

平方取中法

- 先求出关键码的平方，然后取中间若干位构成散列函数。
- 例如：key = 4731，key2 = 22382361，如地址码为3位，则可以取382 为散列地址，即 h(4731) = 382
- 这是一种较常用的构造散列函数的方法。
    - 设计思想是，一个数平方 的中间几位数和每一位都相关，由此使均匀分布的关键码得到的散 列地址也是比较均匀的
- 取的位数由表长决定。

折叠法

- 如果关键码的位数多于地址位数，且关键码中每一位分布均匀时， 此时可以将关键码分成若干部分，其中一部分的长度等于地址位数。 各部分相加，舍弃进位，最后的和作为散列地址。
- used when
    - key has more digits than the address length
    - digits of the key are evenly distributed
- Idea
    - split key into several parts
    - each part has same length as the address
    - add all parts together
    - discard any carry
    - final result is hash address
- 例如：key = 05 8242 2241，地址位数为4。
    - 移位相加： (2241 + 8242 + 05) % 10000 = 0488
    - 间界叠加（隔数反转）：(2241 + 2428 + 05) % 10000 = 4674
        - 隔数反转，即相加时每隔一个数就将数字反转
        - 虽然隔数反转从理论上看来毫无必要，但这个步骤确实为折叠法得到散列 函数提供了一种常用的微调手段。

余数法

- h(key) = key % p
- p的选择非常重要，通常选择小于等于散列表长度m的某个最大素数。
- 散列表长设置为m时，通常取的p值：
    - 

基数转换法

- 将关键码首先看作是另一进制的表示，然后再转换为原来的进制数， 并用数字分析法取若干位作为散列地址。
- 一般转换基数大于原基数，且最好二者互素
- 例如： key = (236075)10，把它看作13进制数 (236075)13,
    - 再转换为10进制：(236075)13 = 2_135+3_134+6_133+7_131+5 = (841547)10
    - 假设地址位数为4，选择 841547 的2~5位
    - 得到散列地址 h(236075) = 4154

#### 碰撞处理

方法

- 开地址法（探查法）：为冲突的数据项再找一个开放的空槽
- 拉链法：将容纳单个数据项的槽扩展为容纳数据项集合（或者对数 据项链表的引用）

开地址法

- 基本思想
    - d0 = h(hey) 称为关键码key的基地址
    - 当碰撞发生时，用某种方法在基本区域内确定一个探查序列。
        - di = d0 + p(key, i)
        - p称为探查函数，di称为后继散列地址
        - store another address in the same table
    - 按照确定探查序列的方式分为：
        - 线性探查法
        - 双散列函数法

- 过程
    - 插入关键码key时，若发生了碰撞：
        - 则按照探查函数生成的探查序列一次查找
        - 将找到的第一个空闲位置di作为key的存储位置
        - 若后续散列地址都不空闲，说明散列表已满，报告溢出
    - 检索关键码key时
        - 依然首先计算基地址，以及相应的探查序列
        - 在探查序列中依次遍历查找关键码key
        - 如果遇到了空闲位置，表示探查序列结束，检索失败

Compute the same **base address** and **probe sequence**

Traverse the probe sequence **in the same order**

If the key is found, the search is **successful**

If an **empty slot** is encountered:

The probe sequence ends

The search **fails** (the key is not in the table)

- - 插入和检索时都需要考虑表满的情况
        - 探查序列可能会进入一个无限循环中
        - 可以限制探查序列的长度

线性探查法 linear probing

- 若在地址为d (d=h(key)) 的单元发生碰撞：
- 则探查序列为：d+1,d+2,…,m-1,0,1,…,d-1 (m为基本存储区的长度
    - 相当于将基本存贮区看作一个循环表，进行顺序遍历。
- 如果从单元d开始探查，查找一遍后又回到地址d，则表示基本存贮 区已经溢出

When a collision occurs at the hash address, the algorithm **checks the next slots one by one** until an empty slot or the target key is found.

- 聚集问题
    - 聚集：哈希值不同的关键码产生的探查序列相互重叠，在 同一个地址序列上堆积，导致很长的探查序列。
    - **Clustering** happens when many keys end up probing **the same or overlapping address sequence**,
        - **Clustering** happens when many keys end up probing **the same or overlapping address sequence**, causing:
        - 可以改进一下探查序列，例如由线性函数改为二次函数，减少重叠
        - Use **quadratic probing**
            - **instead of di = h(key) + i, use di = h(key) + c1·i + c2·i²**
    - 二次聚集：哈希值相同关键码产生的探查序列总是相同的 的，插入哈希值相同的元素（同义词），不可避免地导致 元素堆积在一起，也使得探查序列变长。
        - Keys with the **same hash value** always generate **the same probe sequence**, causing them to pile up together.
            - if h(key1) = h(key2), probe(key1) = probe(key2)
                - 
        - 根本原因在于，探查序列完全由哈希值确定，与关键码值本身无关
            - The fundamental reason is that the probe sequence is completely determined by the hash value and has nothing to do with the actual key.
    - 为了减少二次聚集的产生，可以改进线性探查方法
        - 令探查序列不仅依赖于哈希值，也依赖于关键码值
            - instead of h(key), use i = h1(key) + i · h2(key)
        - 使得同义词也能够产生不同的探查序列，减少聚集

双散列函数法

- 双散列函数法选用两个散列函数h1和h2
    - **Double hashing** is a collision resolution technique in **open addressing** that uses **two hash functions** instead of one.
    - h2 allows for calculating step size for each key. The step size depends on each key, so the step size will change depending on the key, allowing for better dealing of collisions
        - h1(key) → determines the **initial (base) address**
        - h2(key) → determines the **step size** of the probe sequence
    - This makes the probe sequence depend on **both the hash value and the key itself**, which greatly reduces clustering.
- 假设m为散列表长
    - h1产生一个0到m-1之间的数作为地址。
        - Produces a value in \[0, m−1\]
        - This is the **base address** d
    - h2产生一个1到m-1之间的数作为探查序列的间隔
        - h2(key) = key % (m − 1) + 1
        - Produces a value in \[1, m−1\]
        - Used as the **interval (step size)** for probing
        - Never equals 0 (important!)
- 例如，h1 (key)=key%m，h2 (key) = key % (m-1) + 1。
    - 如果d=h1 (key)发生碰撞，则再计算h2 (key)，
    - 产生的探查序列为：(d+h2 (key))%m, (d+2\*h2 (key))%m, …
    - 结果是，探查序列既依赖于哈希值，也依赖于关键码值
- h2产生的间隔必须与m互素
    - H2 must coprime with m

If gcd(h2(key), m) ≠ 1, then:

- - - The probe sequence will cycle through **only a subset** of slots
        - Some positions will **never be visited**
        - Even if empty slots exist, insertion may fail
        - 
    - 为了保证，如果表中存在空闲位置，探查序列总能遍历到它 – 实际中，将 m 设置为素数就可以保证这一点

开地址法：删除元素

- 使用开地址法的哈希表中删除元素时，需要关注两点：
    - 释放的位置要能够为将来所用
    - 删除元素不能影响后续的检索
- 删除元素带来的问题
    - 如果直接删除，K2的所有同义词K2’就无法被查找到
        - because since the position is empty, we can just assume that there are no 同义词 since nothing has ever been placed there, therefore no collision should've happened
- 墓碑
    - 表示该位置上不存在元素，但是探查过程不应该停止在这里
    - 删除元素时：
        - 首先沿着探查序列定位到待删除位置
        - 直接将该位置的值设置为 TOMB 值（特殊标记
    - 插入元素时
        - 仍沿着探查序列遍历。遇到墓碑，应当视为已被占用的位置继续遍历
        - 遇到墓碑直接占用是错误的：插入过程需要确保表中的关键码不重复， 必须遍历整个探查序列直到遇到空位
        - 如果遇到重复元素，应返回插入失败；
        - 遇到空位后，即可确保表中无重复元素，可以插入关键码
            - 如果未曾遇到墓碑，正常插入空位置即可
            - 如果遇到过墓碑，就可以将关键码插入到第一个墓碑的位置

拉链法：指针

- 检索关键码值为key的元素
    - 计算基地址h(key)
    - 在基地址对应的同义词链表中顺序查找该关键码
    - 如果同义词链表为空，或不包含目标关键码，则检索失败
- 插入关键码值为key的元素
    - 首先执行对该元素的查询
    - 如果检索成功，表明关键码重复，插入失败
    - 如果检索失败，就向同义词链表追加关键码值即可
- 删除关键码值为key的元素
    - 首先执行对该元素的查询
    - 如果检索失败，表明表中不存在该元素，删除失败
    - 如果检索成功，在同义词链表中删除该元素即可

拉链法的优势：

- 由于各链表上的结点空间是动态申请的，因此更适应于构造表前无 法确定表长的情况；
- 避免了聚集问题，哈希值不同的关键码的检索过程不会重叠
- 结点的删除操作较方便，不需要设置墓碑作为特殊标记位

拉链法散列表的负载因子为同义词链表的平均长度 n/m。

- n为总关键码数量，m为散列表长度
- 一般设计 n/m 大于1小于10
- 负载因子越高，意味着同义词链表的平均长度越长，插入删除检索 的代价越高

实例：Python中的dict, set

- Python内置了dict 类型，存储一系列 key-value 对，支持按 照关键码 key 的高效检索。
    - dict的实现基于散列表（哈希表），并使用了线性探查的开地址法
    - set类型的实现采取了相同方法，只不过set只需要存储 key，无需存 储 value
- 哈希函数为 h(key) = hash(key) % m，m为哈希表大小
    - Python内置了hash函数，接受不可变对象（数值，字符串，元组） 作为关键码，返回整数哈希值
    - key必须是不可变类型，因为必须保证同一元素的哈希值不会改变
    - 自定义的类型实现_\_hash_\_方法，之后也可以作为hash函数的参数
- dict，set不定长，同样具有动态扩容机制
- 插入元素时，如果散列表的负载因子超过临界值2/3，就会 触发扩容
    - 插入元素时，如果散列表的负载因子超过临界值2/3，就会 触发扩容
- 删除元素则不会触发扩容，因为删除操作不改变散列表的 负载因子

## 第11讲：排序及基本排序算法

### 排序基本概念

- 记录(Record)：进行排序的基本单位
- 关键码(Key)：唯一确定记录的一个或多个域
- 排序码(Sort Key)：记录中作为排序运算依据的一个或多个域
- 序列(Sequence)：线性表，由记录组成的集合
- 排序(Sorting) — 将序列中的记录按照排序码特定的顺序排列起来，即排序码域的值具有不减(或不增)的顺序

排序的目的

- 给定一个序列R ={r1 , r2 , …，rn}，其排序码分别为k ={k1 , k2 , …，kn}，排序的目的就是将**R中的记录按照特定的顺序重新排列**， 形成一个新的有序序列R’= {r’1 , r’2 , …，r’n}
    - 相应排序码为k’ ={k’1 , k’2 , …，k’n}
    - 中k’1≤k’2≤…≤k’n或k’1≥k’2≥…≥k’n ，前者称不减序（也称非递减序）， 后者称不增序（也称非递增序）

正序与逆序

- –“正序”序列 ：待排序序列正好符合排序要求
- “逆序” 序列 ：把待排序序列逆转过来，正好符合排序要求

排序的稳定性

- 在待排序的文件中，若存在多个排序码相同的记录，经过排序后记录的**相对次序保持不变**，则这种排序方法称为是“稳定的”；否则，是 “不稳定的”

#### 排序的种类

- 按排序中涉及的存储器
    - 内排序:待排序的记录在排序过程 中全部存放在内存
    - 外排序:如果排序过程中需要使用 外存的
- 按排序方法
    - 插入排序
    - 选择排序
    - 交换排序
    - 分配排序
    - 归并排序d

排序算法评价

- 排序的两个基本操作：比较和交换

### 插入排序

- 每一步将一个待排序的记录，按其排序码大小插到前面 已经排序文件中的适当位置，直到全部插入完为止。

#### 直接插入排序

基本思想

- 将待排序序列分为已排序和未排序两部分。
- 初始时，已排序部分仅包 含第一个元素，未排序部分包含剩余元素。
- 逐个处理待排序的记录。每步将一个待排序的元素Ri按其排序码Ki大小插入到前面已排序表中的适当位置，直到全部插入完为止。

直接插入排序算法评价

- 算法是稳定的
- 空间代价：O(1)，交换操作需要一个辅助空间
- 时间代价
    - 最佳情况（正序）：n-1次比较，0次交换，O(n)复杂度 –最差情况（逆序）：比较和交换次数为O(n2 )
- 平均情况：O(n2 )
- 当记录数量n较小时，直接插入排序是一 种高效的排序算法！

#### 二分法插入排序

基本思想

- 在直接插入排序的基础上减少比较的次数，即在插入Ri时 改用二分法找插入位置
- 插入记录Ri时，记录集合中子区间{R0 ,R1 ,…,Ri-1 }已经有序 –low =0; high = i-1; mid= (low+high)/2 带入二分检索
    - 找出应该插入的位置；
    - 将原位置的记录向后顺移，将记录Ri插入
- 二分插入排序采用顺序存储结构

note

- 算法是稳定的
- 空间代价：O(1)，算法中有一个辅助空间
- 时间代价
    - 比较次数降为nlogn量级：插入每个记录需O(log i)次比较
    - 移动次数仍为n^2量级：每插入一个记录最多移动i+1次
    - 因此，最佳情况下总时间代价为O(nlog n) ，**最差和平均情况下仍为 O(n^2 )**

#### Shell 排序

- 提出基于直接插入排序的2个性质
    - 在待排序序列较短情形下效率高
    - 在整体有序的情形下时间代价低
- 如何利用这两个性质？
    - 在初始无序时，进行等间隔的小序列分割
        - 先将待排序序列转化为若干小序列，在这些小序列内进行直接插入排序
    - 在整个序列趋向有序后，逐步扩大序列规模
        - 逐渐扩大小序列的规模，而减少小序列个数，使得待排序序列逐渐处于更 有序的状态
    - 最后，对整个序列进行一次完整的插入排序

算法性能分析

- Shell排序算法的速度比直接插入排序快，其时间复杂度分析比较复杂，Shell排序的平均比较次数和平均移动次数都 为n^1.3左右
- Shell排序算法中增加了一个辅助空间，因此算法的辅助空 间为S(n)=O(1)
- Shell排序是不稳定的

### 选择排序

每趟从待排序的记录序列中**选择关键字**最小/大的记录放置到**已排序表的最前位置，**直到全部排完。

#### 直接选择排序

基本思想

- 每一趟在后面n-i个待排记录中选取最小记录和第i个记录互换

具体过程

- 首先，在n个记录中选择最小者与r\[0\]互换；
- 然后，从剩余的n-1个记录中选择最小者与r\[1\]互换；
- 如此下去，直到全部有序为止。

优点

- 实现简单

缺点

- 每趟只能确定一个元素，表长为n时需要n-1趟

直接选择排序性能分析

- 直接选择排序的比较次数与记录的初始状态无关
    - 第i趟排序：从第i个记录开始，顺序比较选择最小关键码记录需 要n-i次比较。
    - 
- 时间复杂度：T(n)=O(n2 )，
- 辅助空间1个记录单位： S(n)=O(1)
- 稳定性：不稳定的排序
    - 不稳定的排序指的是：排序算法在排序过程中，相等元素的相对顺序可能会发生改变。

#### 堆排序

动机：在选择过程中如何利用前面的比较结果来减少比较次数？

堆的定义

最后一行最重要

堆排序的基本思想

1.  对所有记录建立最大堆（O(n)）
2.  取出堆顶的最大记录移到数组末端，放在下标n-1的位置；
3.  重新将剩下的n-1个记录建堆（O(logn)），再取新堆顶最 大的记录，放到数组第n-2位；…；
    1.  不断重复这一操作， 直到堆为空
4.  这时数组正好是按从小到大排序

示例

关键问题

- 如何将原始序列构成初始堆？
    - 初始完全二叉树中，序号为 n/2 ， n/2 +1 …，n-1的结点 为叶子，以其为根的子树必然 为堆。
    - 因此，初始堆建立时，只需要 将所有非终端结点为根的子树 调整为堆。
    - 一句话总结：从最后一个有孩子的节点开始，从后往前，把每个子树都调整成堆，这样最后整个树就是堆了。叶子节点不用管，因为它们自己就是堆。
- 采用“筛选法”建堆
    - 为以Ri 为根的完全二叉树建堆，这时Ri 的左、右子树都是堆，可以把 Ri与其左、右子树根结点R2i+1、R2i+2中最大者交换位置。
    - 若交换位置后破坏了子树的堆特性，则再对这棵子树重复交换过程， 直到以Ri为根结点的子树成为堆

时间效率评价

### 交换排序

两两比较待排序记录的排序码，交换不满足顺序要求的 偶对，直到全部满足为止

#### 冒泡排序

基本思想

- 不停地比较相邻的记录，如果不满足排序要求，就交换相邻记录，直到所 有的记录都已经排好序
- 原理
    - 若序列中有 n 个元素，通常进行 n - 1 趟
        - 第1趟，针对第r\[0\]至r\[n-1\]个元素进行
        - 第2趟，针对第 r\[0\]至r\[n-2\] 个元素进行
        - 第n-1趟，针对第r\[0\]至r\[1\]个元素进行
    - 第i趟进行的过程
        - 针对r\[0\]至r\[n-i\] 元素进行，比较两个相邻的元素。若相邻的元素的相 对位置不正确，则进行交换；否则继续比较下面两个相邻的元素。

冒泡排序算法分析

- 算法是稳定的
- 空间代价：O(1)的临时空间
- 时间代价
    - –交换次数最多为O(n2 )，最少为0，平均为O(n2 )。
    - –最大，最小，平均时间代价均为O(n2 )

冒泡排序方法改进

#### 快速排序

- 可以设置一个标志no_swap表示本次冒泡是否有记录 交换，如果没有交换则表示整个排序过程完成

#### 快速排序

快速排序是对冒泡排序的改进

- 冒泡排序
    - 在相邻两个记录间比较和交换，每次交换只能上移或下移一个位置， 导致总的比较与移动次数增多
- 快速排序又称分区交换排序
    - 设待排序的n个记录{R0 , R1 ,… Rn-1}，选取第一个记录R0为划分基准， 寻找R0的最终位置（一趟快速排序）：
    - {R\[0\], R\[1\], …,R\[i-1\]} 存放的为小于R0的记录
    - {R\[i+1\], R\[i+2\],…,R\[n-1\]}存放的为大于R0的记录
    - R\[i\] 为R0的最终位置

一趟快速排序 process

- 设置变量i = 0，变量j = n-1
- 保存记录temp=R0， R0为空出的位置（空位在前一区）；

### **分配排序**

把排序码分解成若干部分，然后通过对各部分排序码的分 别排序，最终达到整个排序码的排序

分配排序

- **It is sorting with multiple ranking (priority) conditions**
- **、**
- 分配排序：实现多关键码排序的方法
    - 高位优先法
        - 将文件逐层分割成若干子文件，各子文件独立排序；
    - 低位优先法
        - 对每个关键码都是所有记录参加排序，可通过若干次“分配”和 “收集”实现排序。

**基数排序**

- 把每个排序码看成是一个d元组：Ki=(Ki 0 , Ki 1 ,…, Ki d-1 ) 其中每个Ki都是集合{C0，C1，…，Cr-1}中的值 即C0≤Ki j≤Cr-1 (0≤i≤n-1,0≤j≤d-1) ， 其中r称为基数。
- •基数排序的基本思想
    - 排序时先按Ki d-1从小到大将记录分配到r个堆中
    - 然后依次收集，再按Ki d-2分配到r个堆中…
    - 如此反复，直到对Ki 0分配、收集，便得到最终排序序列

**归并排序**

- 把待排序的文件分成若干子文件，每个子文件内排序； 再将已排序的子文件合并，得到完全排序的文件

## **第12讲：图**

### 图的基本概念

图的逻辑结构

- 线性结构：唯一前驱，唯一后继，线性关系
- 树结构：唯一前驱，多个后继，层次关系
- **图结构：多个前驱，多个后继，网状关系**

图的逻辑结构：G = (V, E)

- 图由顶点集合与边集合组成
- V为有穷的顶点集合
- E为边集合，是顶点的偶对（边的始点，边的终点）集合
- 用 |V| 表示顶点的总数，|E| 表示边的总数

不同特点的图：

- 稀疏图(sparse graph) / 稠密图(dense graph)：边数相对较少 / 较多
- 完全图(complete graph)：包含所有可能的边
- 有向图(directed graph) / 无向图(undirected graph)：顶点对有序 / 无序
- 带权图(weighted graph)：边上标有权的图
- 标号图(labeled graph)：各顶点均带有标号的图

无向图

- 若图中每条边都是无方向的，则称为无向图
    - 无向图中的边是由两个顶点组成的无序对
    - 无序对用圆括号表示，如(vi ,vj )；(vi ,vj )和(vj ,vi )代表同一条边
    - vi和vj是相邻结点，(vi ,vj )是与顶点vi和vj相关联的边

有向图：

- 若图中每条边都是有方向的，则称为有向图
    - 有向图中的边是由两个顶点组成的有序对。
    - 有序对用尖括号表示，如&lt; vi ,vj &gt;。vi是边的始点，vj是边的终点
    - &lt; vj ,vi &gt;和&lt; vi ,vj &gt;表示不同的边
    - 边&lt; vi ,vj &gt;与顶点 vi , vj **相关联**

简单图

- 自环：一条边的两个端点是同一个顶点
- 重边：无向图中两个顶点之间有不止一条边，或有向图中两个顶点之间有不止一条同方向的边
- 简单图：不包含自环或重边的图

完全图

- 图中的任意两个顶点之间都存在边
    - 对于有向图：任意两个顶点之间存在任意方向的边
- 记 n = |V|, e =|E|
- 若G是有向图，则0 ≤ e ≤ n(n-1)
    - 有向完全图具有n(n-1)条边
- 若G是无向图，则0 ≤ e ≤ n(n-1)/2
    - 无向完全图具有n(n-1)/2条边
- 在顶点个数相同的图中，完全图具有最多的边
    - 具有4个顶点的无向完全图，边数为:4\*(4-1)/2=6

顶点的度数

- 在无向图中：
    - 与顶点v相关联的边数称为顶点v的度数，记为D(v)
- 在有向图中：
    - 入度：以v为终点的边的数目称为v的入度，记为ID(v)
    - 出度：以v为始点的边的数目称为v的出度，记为OD(v
    - v的度数为其入度和出度之和，即D(v)=ID(v)+OD(v)
- 若图G有n个顶点，e条边，则有
    - 
- 每一条边都参与计算了其两个顶点的度数
    - • 有向图与无向图均满足这一关系

相邻结点

- 在无向图中：
    - 若存在边(x, y)，则顶点x, y互为相邻结点，或者说x, y相邻
- 在有向图中
    - 若存在边，即存在边由x指向y，则顶点y是顶点x的相邻结点
- 相邻结点，也称为邻居、邻居结点、邻点等

子图

- 定义：设有图G=(V，E)和G’=(V’ ，E’)，如果V’是V的子集， E’是E的子集，则称G’是G的子图
- - 有向图G1的若干子图

路径

- 定义：对于无向图G=(V, E)，若存在顶点序列vi0, vi1, …, vin， 使得(vi0 , vi1 ), (vi1 , vi2 ), …, (vin-1 , vin)**都在E中**，则称从**顶点vi0 到vin存在一条路径**。
    - 对于有向图G：只需要将条件修改为：, &lt; vi1 , vi2&gt;, …, 都在E中
- 路径长度：路径上的边数
- 简单路径：路径上的顶点除vi0和vin可以相同外，任意两个 顶点都不相同
- 回路或环：起点和终点相同的简单路径

无向图的连通性

- 无向图的连通性
    - 连通：无向图G=(V，E)中，若从**vi到vj有一条路径**(从vj到vi也一定有 一条路径)，则称vi和vj是连通的。
    - 连通图：若V(G)中**任意两个不同的顶点vi和vj都是连通的**(即有路径)， 则称G为连通图。
    - 连通分量：无向图G的极大连通子图G’（极大：即任意增加G中结点 和边到G’**所得到的子图都不再连通**），称为G的连通分量
- 连通图只有一个连通分量，就是其自身
- 非连通的无向图有多个连通分量

有向图的连通性

- 有向图的连通性
    - 强连通图：有向图G=(V，E)中，若V中任**意两个不同的顶点vi和vj都 存在从vi到vj以及从vj和vi的路径**，则称图G是强连通图。
    - 强连通分量：有向图G的极大强连通子图称为图G的强连通分量
    - 弱连通图：将有向图G=(V, E)中的所有有向边替换为无向边，得到 的无向图如果是连通图，则称有向图G是弱连通图。
    - 弱连通分量：有向图的G的极大弱连通子图称为图G的弱连通分量
- 强连通图只有一个强连通分量，就是其自身
- 非强连通的有向图有多个强连通分量

图的根

- 定义：有向图中，若存在一顶点v，从该顶点到图中其它 所有顶点都存在路径，则称此有向图为有根图，v称为图 的根
- 图中的根可能 不唯一

带权图

- 若给图的每条边都赋上一个权值，则称该图为带权图
    - 可以是无向图或者有向图
    - 通常这一权重具有实际意义，例如顶点间的距离、通信的花费、或 者边所表示的关系的强弱等
- 连通的带权图也称为网络

### 图的存储方式

存储结构

- 图逻辑结构中，每个元素可以有任意多个相邻结点，且需 要区分边是否有向，因而图的存储方法也更复杂。
- 应根据具体的应用和施加的操作选择不同的存储表示法
    - **邻接矩阵表示法**
    - **邻接表表示法**

#### 邻接矩阵表示法

- 设G=(V, E)为具有n个顶点的图，其邻接矩阵(Adjacency matrix) A 为如下定义的 n 阶方阵
- 
- 存储图的邻接矩阵，就维护了所有顶点以及顶点之间的相 邻关系
    - 顶点信息：依次标号为0 ~ n-1
    - 关系信息：每条边都对应到邻接矩阵中的一个非零元素
- 对于不带权的无向图，邻接矩阵A是对称的；对于带权图 或者有向图，A一般非对称

邻接矩阵表示法：实现

- 最直观实现方法：使用一个嵌套列表 L 存储邻接矩阵 A
    - 每一个子列表存储邻接矩阵的一行
    - L\[i\]\[j\] = A\[i, j\]
- 计算结点的度数：
    - 无向图中第 i 个结点的度数 D(vi )：第 i 行/列中非零元素的个数
    - 有向图中第 i 个结点的出度 OD(vi)：第 i 行中非零元素的个数
    - 有向图中第 i 个结点的入度 ID(vi)：第 i 列中非零元素的个数
- 寻找结点的相邻结点：
    - 无向图中第 i 个结点的相邻结点：第 i 行中非零元素对应的下标
    - 有向图中第 i 个结点的相邻节点：第 i 行中非零元素对应的下标

#### 邻接表表示法

- 为了记录图中所有的边，可以为**每个顶点 x 设置一个线性表记录** x 的所有相邻结点。这种图的表示方式称为**邻接表**
    - 该线性表是不定长的，x 有几个相邻结点，对应线性表中就有几个 元素
    - 线性表中的一个元素记录了一个相邻结点 y，表示存在边 (x, y) 或
    - 对于有权图，或者边附带有其他信息，也可以存储在该线性表中

邻接表表示法：实现

- 邻接表表示法同样可以用嵌套列表实现
- 对于嵌套列表G，G\[i\] 就是一个一维列表，称为G的一行
    - G\[i\] 中存放结点 Vi 的所有相邻结点
    - 对于带权图，G\[i\]中的元素可以是元组，即（相邻结点，对应边权）
    - 具体实现时，如果结点没有额外信息，G\[i\]中只存放结点标号即可； 否则，也可以首先将结点实现为类，G\[i\] 中存放结点对象的引用
- Python中的列表本身就是不定长的，各行之间的长度也通 常不同，G本身通常不构成一个矩阵
- 邻接表表示法就是基于相邻结点进行存储的。该表示法下， **计算结点的度数、寻找结点的相邻结点**等操作更加简单

邻接矩阵表示法 vs 邻接表表示法

- 用 n 表示结点数量，e 表示边数量
- 构建一个图的复杂度
    - 邻接矩阵表示法：时间、空间复杂度都是 O(n2 ) 的。这意味着对于 任何问题，如果采用**这种存储方式，时间复杂度都至少是 O(n^2 )**
    - 邻接表表示法：**时间、空间复杂度都是 O(n+e)** 的。尽管 e 理论上能 够达到 n 2 的量级，但实际大多数情况下远小于 n 2
- 对任意的两个结点 Vi , Vj，查询它们之间边的情况
    - 邻接矩阵表示法：**O(1) 的复杂度就可以访问 A\[i\]\[j\] 元素**
    - 邻接表表示法：**需要遍历 G\[i\] 中的元素，复杂度为 O(n)**
- 对于有向图，求顶点 Vi 的入度
    - 邻接矩阵表示法：查询邻接矩阵A的第 i 列即可，复杂度为O(n)
    - 邻接表表示法：遍历每一行查找 Vi，复杂度为O(n+e)
- 查找顶点 Vi 的相邻结点，以及边的权值
    - 邻接矩阵表示法：查询邻接矩阵的第 i 行即可
    - 邻接表表示法：查询邻接表的第 i 行即可
    - 理论上二者的复杂度都是 O(n)。但是，邻接表只需要存储图中存在 边，而邻接矩阵中还包含若干个 0 或无穷。相比之下，前者的信息 更加紧凑，查询也会更快
- 存储稀疏图的效率
    - 邻接矩阵表示法：时间空间复杂度与图是否稀疏无关，O(n2 )
    - 邻接表表示法：每条边只需要存储一次（有向图）或两次（无向 图），复杂度为 O(n+e)。如果 e 远小于 n 2，效率能够大大提高

### **图的搜索与遍历**

定义

- 图的搜索：
    - 从图中给定一个起始顶点出发，**寻找一条到目标顶点 的路径**，称为图的搜索
- 图的遍历
    - 从图中某一顶点出发，按照某种方式系统地访问图中所有顶点，使得每一个顶点被访问且仅被访问一次，称为图的遍历， 也称为图的周游。‘
- 搜索由两种基本策略
    - 深度优先搜索（Depth First Search, DFS）
    - 广度优先搜索（Breadth First Search, BFS）

图的搜索问题

- 对于许多问题的本质，都可以抽象为在**图上的两个顶点之 间寻找路径**
    - 可以从问题中抽象出一系列状态，对应图中的顶点集合
    - 状态之间的可以转换，对应图中的边集合
    - 问题本身就是求解由一个状态迁移到另一个状态的过程
    - 这一表示过程就是问题的建模

#### 深度优先搜索 DFS

- 能向前走就向前走， 无法前进时就回溯到之前的位置，尝试其他的路径
- 在搜索的过程需要记录已经走过的节点，做过的节点不可能重复走到，
- 无论选择过程如何，搜索过程中走过的所有结点以及边， 都会构成一个树，称为搜索树

以上就是一个搜索树

伪代码

对于一些问题（如前述的24点问题），问题建模的图为有 向无环图（DAG, Directed Acyclic Graph），**由于图中无环， 搜索时就不必维护 visited 集合**

深度优先搜索的时间复杂度

- 初始化所有结点的时间复杂度为 O(n)
- 最坏情况下，每个结点都会被访问一次（进入递归），每条边都被 检查一次
- **时间复杂度为 O(n+e）**

深度优先搜索：启发式搜索

- 为了尽快地找到可行路径或者最短路径，在路径选择时， **可以针对不同的具体问题，使用经验法则或代价估计来指 导搜索的方向**，从而减小搜索的范围，更快达到目标
    - 采取的经验法则，**可以是经过数学证明的严谨性质，也可以是只基于经验的规则**。它们都统称为启发式规则（Heuristics）
    - 严格证明过的启发式规则可以保证得到最优解
    - 启发式搜索也可以视为广义的剪枝策略

#### 广度优先搜索

- 广度优先搜索能**保证得到长度最短的路径**
- 广度优先搜索的关键在于将顶点“分层”
    - 对应搜索树中结点的层次
    - 起点位于第 0 层，距离为 1 的顶点位于第一层，依此类推
    - 按层次从低到高扩展顶点，并用队列存放；先搜索层数较低的结点， 后搜索层数较高的结点，从而保证能够找到最短路径
    - 为了记录最短路径，顶点入队时需要记录其在搜索树中的父结点

use the dictionary to find the shortest path

\\

广度优先搜索的时间复杂度分析

- 初始化结点的代价为 O(n)
- 迭代搜索过程中，每个结点至多入队 / 出队一次。因此，入队 / 出队 的代价为O(n)
- 对于队首元素，要对其所有邻居结点进行判断。该步骤中总的判断 次数取决于图中边的总数，即代价为 O(e)
- 重构路径的代价为 O(n)

广度优先搜索的时间复杂度为 O(n+e)

广度优先遍历

## 第十三讲：最小生成树

### 图的最小生成树

#### 生成树（Spanning Tree）

- 对于**带权无向连通图** G=(V, E)，以及 G 的一个子图 G’=(V’, E’)，若 V=V’，且 G’ 是**不含回路的连通图**，则称 G’ 是 G 的生成树
- 连通图的生成树是**连通图的一个极小连通子图**，它含有图中的全部 n 个顶点，以及**足以构成一棵树的 n-1 条边**。
    - 增加一条边，则必定构成环
    - 去掉一条边，则连通图变为不连通的
- 基于 DFS 以及 BFS 得到的搜索树，就是图的生成树，因此也称为 DFS 生成树、BFS 生成树
- 对于非连通图，从任一顶点出发无法访问到所有的顶点， 只能得到各连通分量的生成树所组成的生成森林

#### 最小生成树（Minimum Spanning Tree, MST）

- 定义生成树的权值为其中所有边的**权值之和**，则 G 的所有生成树中， **权值最小**的生成树称为图 G 的最小生成树
- 最小生成树并不唯一
- 最小生成树的性质
    - G=(V, E) 是带权连通无向图，U 是 V 的任意非空子集，考 虑所有一端在 U 中而另一端不在 U 中的边，其中权值最 小的边 X 一定属于 G 的一棵最小生成树 T。
    - 
- 将图 G 任意地划分成两部分 – 由于 G 是连通的，这两部分之间必然存在边作为“桥梁” – **任意一个权值最小的“桥梁”，一定属于某棵最小生成树 T**

### **Prim 算法**

- Prim 算法是求解最小生成树问题的**贪心算法**，其基本思路 如下：
    - 假设G = (V, E)是有n个节点的带权连通图，为构建 G = (V, E) 的一棵 最小生成树 T = (V’, E’)，将 V’ 初始化为包含V中一个顶点（任意一 个顶点）的集合，将 E’ 初始化为空集
    - 每次从 V – V’ （即在T外的顶点）中，寻找一个“距离 V’ 最近”的 结点，加入 V’ 中；对应关联的边加入 E’ 中
    - 距离 V’ 最近的含义为，与 V’ 中的结点相邻，且边权最小
    - 可以理解为，每次从跨越了 V’ 与 V – V’ 的边中，寻找权值最小的，将其关 联的顶点加入 V’ 中，将这条边本身加入 E’ 中
    - 重复该步骤 n – 1次，就得到了最小生成树 T

Prim算法的正确性

- 归纳证明：每次向 V’ 中加入结点，并将对应的边加入 E’ 后，总是存在一棵最小生成树 T，使得 G’=(V’, E’) 为 T 的 子图。从而最终构建的 G’ 是一棵最小生成树
    - 
- 归纳假设：假设加入第 𝑘 个结点后成立该性质，即 𝐺𝑘 ′ = (𝑉𝑘 ′ , 𝐸𝑘 ′ ) 是最小生成树 𝑇𝑘 的子图
    - 

### Kruskal 算法

贪心算法，算法：

- 为构建 G = (V, E) 的一棵最小生成树 T = (V’, E’)，将 V’ 初始化为 V， 将 E’ 初始化为空集，即 G’ 初始时具有 n 个连通分量
- 每次从边集 E 中取出权值最小的边 e 。如果 e 关联的两个顶点在 G’ 中属于不同的连通分量，就将 e 加入到 E’ 中
- 不断重复上述步骤，直到图 G’ 成为连通图
- 

Kruskal算法的正确性

- 每次向 E’ 中加入边后，总是存在一棵 最小生成树 T，使得 G’=(V, E’) 为 T 的子图。从而最终构建 的 G’ 是一棵最小生成树
- 假设加入第 𝑘 个结点后成立该性质，即 𝐺𝑘 ′ = (𝑉, 𝐸𝑘 ′ ) 是最小生成树 𝑇𝑘 的子图